{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8480b3a3",
   "metadata": {},
   "source": [
    "# Graph Analysis EDA\n",
    "This notebook performs exploratory data analysis on the drug-disease knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbe5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5baaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the knowledge graph\n",
    "graph_path = Path('../data/processed/graph/knowledge_graph.graphml')\n",
    "\n",
    "print(f\"Loading graph from {graph_path}...\")\n",
    "G = nx.read_graphml(graph_path)\n",
    "print(f\"Graph loaded with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40108295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic graph statistics\n",
    "def print_graph_stats(G):\n",
    "    print(\"Graph Statistics:\")\n",
    "    print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"  Edges: {G.number_of_edges()}\")\n",
    "    print(f\"  Is Directed: {nx.is_directed(G)}\")\n",
    "    print(f\"  Connected Components: {nx.number_connected_components(G.to_undirected())}\")\n",
    "    \n",
    "    # Largest connected component\n",
    "    Gcc = max(nx.connected_components(G.to_undirected()), key=len)\n",
    "    print(f\"  Largest Component Size: {len(Gcc)} nodes ({len(Gcc)/G.number_of_nodes()*100:.2f}%)\")\n",
    "    \n",
    "    # Node degree statistics\n",
    "    degrees = [d for _, d in G.degree()]\n",
    "    print(f\"  Average Degree: {np.mean(degrees):.2f}\")\n",
    "    print(f\"  Min Degree: {min(degrees)}\")\n",
    "    print(f\"  Max Degree: {max(degrees)}\")\n",
    "    print(f\"  Median Degree: {np.median(degrees):.2f}\")\n",
    "    \n",
    "    # Density\n",
    "    print(f\"  Graph Density: {nx.density(G):.6f}\")\n",
    "\n",
    "print_graph_stats(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee001f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze node types\n",
    "def analyze_node_types(G):\n",
    "    node_types = {}\n",
    "    for node, attrs in G.nodes(data=True):\n",
    "        node_type = attrs.get('type', 'unknown')\n",
    "        node_types[node_type] = node_types.get(node_type, 0) + 1\n",
    "    \n",
    "    return pd.DataFrame.from_dict(node_types, orient='index', columns=['count']).sort_values('count', ascending=False)\n",
    "\n",
    "node_types_df = analyze_node_types(G)\n",
    "print(\"\\nNode Types:\")\n",
    "display(node_types_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae164592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot node type distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "node_types_df.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Node Types')\n",
    "plt.xlabel('Node Type')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/node_type_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1170194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze edge types\n",
    "def analyze_edge_types(G):\n",
    "    edge_types = {}\n",
    "    for _, _, attrs in G.edges(data=True):\n",
    "        edge_type = attrs.get('type', 'unknown')\n",
    "        edge_types[edge_type] = edge_types.get(edge_type, 0) + 1\n",
    "    \n",
    "    return pd.DataFrame.from_dict(edge_types, orient='index', columns=['count']).sort_values('count', ascending=False)\n",
    "\n",
    "edge_types_df = analyze_edge_types(G)\n",
    "print(\"\\nEdge Types:\")\n",
    "display(edge_types_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot edge type distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "edge_types_df.plot(kind='bar', color='lightgreen')\n",
    "plt.title('Distribution of Edge Types')\n",
    "plt.xlabel('Edge Type')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/edge_type_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9207bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze node degree distribution by type\n",
    "def analyze_node_degree_by_type(G):\n",
    "    node_degree_by_type = {}\n",
    "    \n",
    "    for node, attrs in G.nodes(data=True):\n",
    "        node_type = attrs.get('type', 'unknown')\n",
    "        degree = G.degree(node)\n",
    "        \n",
    "        if node_type not in node_degree_by_type:\n",
    "            node_degree_by_type[node_type] = []\n",
    "        \n",
    "        node_degree_by_type[node_type].append(degree)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {}\n",
    "    for node_type, degrees in node_degree_by_type.items():\n",
    "        stats[node_type] = {\n",
    "            'count': len(degrees),\n",
    "            'mean': np.mean(degrees),\n",
    "            'median': np.median(degrees),\n",
    "            'min': min(degrees),\n",
    "            'max': max(degrees),\n",
    "            'std': np.std(degrees)\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame.from_dict(stats, orient='index')\n",
    "\n",
    "node_degree_stats = analyze_node_degree_by_type(G)\n",
    "print(\"\\nNode Degree Statistics by Type:\")\n",
    "display(node_degree_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84847c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot node degree statistics\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=node_degree_stats.reset_index(), x='index', y='mean')\n",
    "plt.title('Average Node Degree by Type')\n",
    "plt.xlabel('Node Type')\n",
    "plt.ylabel('Average Degree')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/avg_degree_by_type.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fce47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze drug-disease paths\n",
    "def find_paths_between_types(G, source_type, target_type, max_length=3):\n",
    "    \"\"\"Find paths between nodes of specified types up to a maximum length\"\"\"\n",
    "    paths = []\n",
    "    path_lengths = []\n",
    "    path_patterns = []\n",
    "    \n",
    "    # Get nodes of each type\n",
    "    source_nodes = [n for n, attrs in G.nodes(data=True) if attrs.get('type') == source_type]\n",
    "    target_nodes = [n for n, attrs in G.nodes(data=True) if attrs.get('type') == target_type]\n",
    "    \n",
    "    # Sample to limit computational load\n",
    "    max_samples = min(100, len(source_nodes))\n",
    "    sampled_sources = np.random.choice(source_nodes, max_samples, replace=False)\n",
    "    \n",
    "    for source in sampled_sources:\n",
    "        for target in target_nodes[:10]:  # Limit targets to first 10 for each source\n",
    "            try:\n",
    "                # Find shortest path\n",
    "                path = nx.shortest_path(G, source=source, target=target)\n",
    "                if len(path) <= max_length + 1:  # +1 because path includes nodes\n",
    "                    paths.append(path)\n",
    "                    path_lengths.append(len(path) - 1)  # Convert to edge count\n",
    "                    \n",
    "                    # Create path pattern (sequence of node types)\n",
    "                    pattern = []\n",
    "                    for node in path:\n",
    "                        node_type = G.nodes[node].get('type', 'unknown')\n",
    "                        pattern.append(node_type)\n",
    "                    \n",
    "                    path_patterns.append('->'.join(pattern))\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "    \n",
    "    return paths, path_lengths, path_patterns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze drug-disease paths\n",
    "if 'drug' in node_types_df.index and 'disease' in node_types_df.index:\n",
    "    print(\"\\nAnalyzing paths between drugs and diseases...\")\n",
    "    paths, path_lengths, path_patterns = find_paths_between_types(G, 'drug', 'disease', max_length=4)\n",
    "    \n",
    "    if paths:\n",
    "        print(f\"Found {len(paths)} paths between drugs and diseases (max length 4)\")\n",
    "        \n",
    "        # Analyze path lengths\n",
    "        path_length_counts = Counter(path_lengths)\n",
    "        path_length_df = pd.DataFrame.from_dict(path_length_counts, orient='index', columns=['count']).sort_index()\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        path_length_df.plot(kind='bar', color='coral')\n",
    "        plt.title('Distribution of Path Lengths (Drug to Disease)')\n",
    "        plt.xlabel('Path Length')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../docs/figures/drug_disease_path_length.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyze path patterns\n",
    "        path_pattern_counts = Counter(path_patterns)\n",
    "        common_patterns = pd.DataFrame.from_dict(path_pattern_counts, orient='index', columns=['count']).sort_values('count', ascending=False).head(10)\n",
    "        \n",
    "        print(\"\\nMost Common Path Patterns (Drug to Disease):\")\n",
    "        display(common_patterns)\n",
    "else:\n",
    "    print(\"Either drug or disease nodes are missing from the graph\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a811f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network visualization of a subgraph\n",
    "def visualize_subgraph(G, start_node=None, n_nodes=50, node_size_factor=100, edge_width=1.0):\n",
    "    \"\"\"Visualize a subgraph starting from a specific node or a random node\"\"\"\n",
    "    if start_node is None:\n",
    "        start_node = np.random.choice(list(G.nodes()))\n",
    "    \n",
    "    # Extract a subgraph using BFS\n",
    "    nodes = set([start_node])\n",
    "    frontier = [start_node]\n",
    "    \n",
    "    while len(nodes) < n_nodes and frontier:\n",
    "        current = frontier.pop(0)\n",
    "        neighbors = list(G.neighbors(current))\n",
    "        \n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in nodes:\n",
    "                nodes.add(neighbor)\n",
    "                frontier.append(neighbor)\n",
    "                \n",
    "                if len(nodes) >= n_nodes:\n",
    "                    break\n",
    "    \n",
    "    # Create the subgraph\n",
    "    H = G.subgraph(nodes)\n",
    "    \n",
    "    # Prepare node colors and sizes based on type\n",
    "    color_map = {\n",
    "        'drug': 'skyblue',\n",
    "        'protein': 'lightgreen',\n",
    "        'disease': 'salmon',\n",
    "        'pathway': 'gold',\n",
    "        'category': 'violet',\n",
    "        'unknown': 'gray'\n",
    "    }\n",
    "    \n",
    "    node_colors = []\n",
    "    node_sizes = []\n",
    "    node_labels = {}\n",
    "    \n",
    "    for node in H.nodes():\n",
    "        node_type = H.nodes[node].get('type', 'unknown')\n",
    "        node_colors.append(color_map.get(node_type, 'gray'))\n",
    "        \n",
    "        # Node size based on degree\n",
    "        node_sizes.append(H.degree(node) * node_size_factor)\n",
    "        \n",
    "        # Node labels\n",
    "        node_labels[node] = H.nodes[node].get('name', node)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    pos = nx.spring_layout(H, seed=42)\n",
    "    \n",
    "    nx.draw_networkx_nodes(H, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8)\n",
    "    nx.draw_networkx_edges(H, pos, width=edge_width, alpha=0.5, arrows=True)\n",
    "    nx.draw_networkx_labels(H, pos, labels=node_labels, font_size=8, font_weight='bold')\n",
    "    \n",
    "    # Create legend for node types\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, \n",
    "                                   markersize=10, label=node_type)\n",
    "                       for node_type, color in color_map.items() if node_type in [H.nodes[n].get('type', 'unknown') for n in H.nodes()]]\n",
    "    \n",
    "    plt.legend(handles=legend_elements, loc='upper right')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Subgraph Starting from {node_labels[start_node]}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/figures/subgraph_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to find a drug node to start visualization\n",
    "drug_nodes = [n for n, attrs in G.nodes(data=True) if attrs.get('type') == 'drug']\n",
    "if drug_nodes:\n",
    "    visualize_subgraph(G, start_node=drug_nodes[0], n_nodes=30)\n",
    "else:\n",
    "    visualize_subgraph(G, n_nodes=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bccb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrality analysis\n",
    "def analyze_centrality(G, top_n=20):\n",
    "    \"\"\"Analyze centrality measures for the graph\"\"\"\n",
    "    print(\"Calculating centrality measures...\")\n",
    "    \n",
    "    # Limit to largest connected component for centrality calculations\n",
    "    largest_cc = max(nx.connected_components(G.to_undirected()), key=len)\n",
    "    H = G.subgraph(largest_cc).copy()\n",
    "    \n",
    "    # Calculate centrality measures\n",
    "    degree_centrality = nx.degree_centrality(H)\n",
    "    betweenness_centrality = nx.betweenness_centrality(H, k=100)  # Use k to limit computation\n",
    "    eigenvector_centrality = nx.eigenvector_centrality_numpy(H)\n",
    "    \n",
    "    # Combine results\n",
    "    centrality_df = pd.DataFrame({\n",
    "        'degree': pd.Series(degree_centrality),\n",
    "        'betweenness': pd.Series(betweenness_centrality),\n",
    "        'eigenvector': pd.Series(eigenvector_centrality)\n",
    "    })\n",
    "    \n",
    "    # Add node attributes\n",
    "    node_types = []\n",
    "    node_names = []\n",
    "    \n",
    "    for node in centrality_df.index:\n",
    "        node_types.append(H.nodes[node].get('type', 'unknown'))\n",
    "        node_names.append(H.nodes[node].get('name', node))\n",
    "    \n",
    "    centrality_df['type'] = node_types\n",
    "    centrality_df['name'] = node_names\n",
    "    \n",
    "    # Get top nodes by each measure\n",
    "    top_degree = centrality_df.sort_values('degree', ascending=False).head(top_n)\n",
    "    top_betweenness = centrality_df.sort_values('betweenness', ascending=False).head(top_n)\n",
    "    top_eigenvector = centrality_df.sort_values('eigenvector', ascending=False).head(top_n)\n",
    "    \n",
    "    return centrality_df, top_degree, top_betweenness, top_eigenvector\n",
    "\n",
    "centrality_df, top_degree, top_betweenness, top_eigenvector = analyze_centrality(G)\n",
    "\n",
    "print(\"\\nTop Nodes by Degree Centrality:\")\n",
    "display(top_degree[['name', 'type', 'degree']])\n",
    "\n",
    "print(\"\\nTop Nodes by Betweenness Centrality:\")\n",
    "display(top_betweenness[['name', 'type', 'betweenness']])\n",
    "\n",
    "print(\"\\nTop Nodes by Eigenvector Centrality:\")\n",
    "display(top_eigenvector[['name', 'type', 'eigenvector']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c68340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot centrality distributions by node type\n",
    "def plot_centrality_by_type(centrality_df, measure='degree'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Group by type and calculate statistics\n",
    "    grouped = centrality_df.groupby('type')[measure].agg(['mean', 'median', 'std'])\n",
    "    sorted_grouped = grouped.sort_values('mean', ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    ax = sns.barplot(x=sorted_grouped.index, y=sorted_grouped['mean'])\n",
    "    \n",
    "    # Add error bars\n",
    "    ax.errorbar(\n",
    "        x=range(len(sorted_grouped)), \n",
    "        y=sorted_grouped['mean'], \n",
    "        yerr=sorted_grouped['std'],\n",
    "        fmt='none', \n",
    "        color='black', \n",
    "        capsize=5\n",
    "    )\n",
    "    \n",
    "    plt.title(f'{measure.capitalize()} Centrality by Node Type')\n",
    "    plt.xlabel('Node Type')\n",
    "    plt.ylabel(f'Mean {measure.capitalize()} Centrality')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../docs/figures/{measure}_centrality_by_type.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot centrality measures by node type\n",
    "plot_centrality_by_type(centrality_df, measure='degree')\n",
    "plot_centrality_by_type(centrality_df, measure='betweenness')\n",
    "plot_centrality_by_type(centrality_df, measure='eigenvector')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5800ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore potential drug-disease pairs for prediction\n",
    "def identify_prediction_candidates(G, max_path_length=3):\n",
    "    \"\"\"Identify potential drug-disease pairs for prediction based on network structure\"\"\"\n",
    "    drug_nodes = [n for n, attrs in G.nodes(data=True) if attrs.get('type') == 'drug']\n",
    "    disease_nodes = [n for n, attrs in G.nodes(data=True) if attrs.get('type') == 'disease']\n",
    "    \n",
    "    # Limit to a sample for computational feasibility\n",
    "    sample_drugs = drug_nodes[:50] if len(drug_nodes) > 50 else drug_nodes\n",
    "    sample_diseases = disease_nodes[:50] if len(disease_nodes) > 50 else disease_nodes\n",
    "    \n",
    "    # Check for existing direct connections\n",
    "    direct_connections = set()\n",
    "    for drug in sample_drugs:\n",
    "        for disease in sample_diseases:\n",
    "            if G.has_edge(drug, disease) or G.has_edge(disease, drug):\n",
    "                direct_connections.add((drug, disease))\n",
    "    \n",
    "    # Find potential pairs based on shared neighbors\n",
    "    potential_pairs = []\n",
    "    \n",
    "    for drug in sample_drugs:\n",
    "        drug_name = G.nodes[drug].get('name', drug)\n",
    "        drug_neighbors = set(G.neighbors(drug))\n",
    "        \n",
    "        for disease in sample_diseases:\n",
    "            # Skip if direct connection exists\n",
    "            if (drug, disease) in direct_connections:\n",
    "                continue\n",
    "                \n",
    "            disease_name = G.nodes[disease].get('name', disease)\n",
    "            disease_neighbors = set(G.neighbors(disease))\n",
    "            \n",
    "            # Calculate shared neighbors\n",
    "            shared = drug_neighbors.intersection(disease_neighbors)\n",
    "            \n",
    "            if shared:\n",
    "                # Calculate Jaccard similarity\n",
    "                jaccard = len(shared) / len(drug_neighbors.union(disease_neighbors))\n",
    "                \n",
    "                # Get types of shared neighbors\n",
    "                shared_types = [G.nodes[n].get('type', 'unknown') for n in shared]\n",
    "                type_counts = Counter(shared_types)\n",
    "                \n",
    "                potential_pairs.append({\n",
    "                    'drug_id': drug,\n",
    "                    'drug_name': drug_name,\n",
    "                    'disease_id': disease,\n",
    "                    'disease_name': disease_name,\n",
    "                    'shared_count': len(shared),\n",
    "                    'jaccard': jaccard,\n",
    "                    'shared_types': dict(type_counts)\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame and sort\n",
    "    if potential_pairs:\n",
    "        pairs_df = pd.DataFrame(potential_pairs)\n",
    "        pairs_df = pairs_df.sort_values('jaccard', ascending=False)\n",
    "        return pairs_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have both drugs and diseases in the graph\n",
    "if 'drug' in node_types_df.index and 'disease' in node_types_df.index:\n",
    "    print(\"\\nIdentifying potential drug-disease pairs for prediction...\")\n",
    "    prediction_candidates = identify_prediction_candidates(G)\n",
    "    \n",
    "    if not prediction_candidates.empty:\n",
    "        print(f\"Found {len(prediction_candidates)} potential drug-disease pairs for prediction\")\n",
    "        print(\"\\nTop candidates by Jaccard similarity:\")\n",
    "        display(prediction_candidates.head(10))\n",
    "        \n",
    "        # Plot distribution of Jaccard similarities\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(prediction_candidates['jaccard'], bins=20, kde=True)\n",
    "        plt.title('Distribution of Jaccard Similarities for Potential Drug-Disease Pairs')\n",
    "        plt.xlabel('Jaccard Similarity')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../docs/figures/jaccard_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot shared neighbor types\n",
    "        shared_types = prediction_candidates['shared_types'].apply(pd.Series).fillna(0).sum()\n",
    "        shared_types = shared_types.sort_values(ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shared_types.plot(kind='bar', color='teal')\n",
    "        plt.title('Types of Shared Neighbors Between Drug-Disease Pairs')\n",
    "        plt.xlabel('Node Type')\n",
    "        plt.ylabel('Total Count')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../docs/figures/shared_neighbor_types.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No potential drug-disease pairs found. This could be due to a small sample or disconnected graph.\")\n",
    "else:\n",
    "    print(\"Either drug or disease nodes are missing from the graph\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary of findings\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"KNOWLEDGE GRAPH ANALYSIS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nThe knowledge graph contains {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "print(f\"Node types: {', '.join(node_types_df.index)}\")\n",
    "print(f\"Edge types: {', '.join(edge_types_df.index)}\")\n",
    "\n",
    "# Summarize node degree statistics\n",
    "print(\"\\nNode degree statistics:\")\n",
    "for node_type, row in node_degree_stats.iterrows():\n",
    "    print(f\"  {node_type}: mean={row['mean']:.2f}, median={row['median']:.1f}, max={row['max']}\")\n",
    "\n",
    "# Summarize centrality findings\n",
    "if not centrality_df.empty:\n",
    "    print(\"\\nMost central entities:\")\n",
    "    \n",
    "    top_degree_node = top_degree.iloc[0]\n",
    "    print(f\"  Most connected: {top_degree_node['name']} ({top_degree_node['type']}) with {top_degree_node['degree']:.4f} degree centrality\")\n",
    "    \n",
    "    top_betweenness_node = top_betweenness.iloc[0]\n",
    "    print(f\"  Most bridging: {top_betweenness_node['name']} ({top_betweenness_node['type']}) with {top_betweenness_node['betweenness']:.4f} betweenness centrality\")\n",
    "    \n",
    "    top_eigenvector_node = top_eigenvector.iloc[0]\n",
    "    print(f\"  Most influential: {top_eigenvector_node['name']} ({top_eigenvector_node['type']}) with {top_eigenvector_node['eigenvector']:.4f} eigenvector centrality\")\n",
    "\n",
    "# Summarize drug-disease relationships\n",
    "if 'drug' in node_types_df.index and 'disease' in node_types_df.index:\n",
    "    drug_count = node_types_df.loc['drug', 'count']\n",
    "    disease_count = node_types_df.loc['disease', 'count']\n",
    "    print(f\"\\nThe graph contains {drug_count} drugs and {disease_count} diseases.\")\n",
    "    \n",
    "    if not prediction_candidates.empty:\n",
    "        print(f\"Identified {len(prediction_candidates)} potential drug-disease pairs for prediction.\")\n",
    "        print(f\"Top candidate: {prediction_candidates.iloc[0]['drug_name']} - {prediction_candidates.iloc[0]['disease_name']} (Jaccard: {prediction_candidates.iloc[0]['jaccard']:.4f})\")\n",
    "\n",
    "print(\"\\nRecommendations for model development:\")\n",
    "print(\"  1. Use network centrality to prioritize important entities in the graph\")\n",
    "print(\"  2. Consider path-based features for drug-disease interaction prediction\")\n",
    "print(\"  3. Incorporate node type information in the graph neural network design\")\n",
    "print(\"  4. Pay attention to multi-hop relationships between drugs and diseases\")\n",
    "print(\"  5. Leverage shared protein targets as important prediction signals\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d1be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821b44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3efc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00607cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
