#!/usr/bin/env python3
"""
üöÄ BLAZING FAST MEMGRAPH LOADER - ULTRA OPTIMIZED üöÄ 
Hardware-optimized for AMD Ryzen 7 4800H CPU (8 cores/16 threads, 16GB RAM)
GPU-accelerated where possible using PyTorch/CUDA
BLAZING FAST EDGE CREATION OPTIMIZED FOR 2000+ EDGES/SEC
"""

import pandas as pd
import numpy as np
from gqlalchemy import Memgraph
import logging
import time
import gc
import psutil
from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor
from multiprocessing import cpu_count
import os
import argparse
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
from dataclasses import dataclass
import threading
from tenacity import retry, stop_after_attempt, wait_exponential
import signal
import sys

# Try to import GPU acceleration libraries
GPU_AVAILABLE = False
try:
    import torch
    if torch.cuda.is_available():
        GPU_AVAILABLE = True
        print(f"üî• GPU acceleration ENABLED! CUDA device: {torch.cuda.get_device_name()}")
    else:
        print("‚ö†Ô∏è  PyTorch available but no CUDA device found")
except ImportError:
    print("‚ö†Ô∏è  PyTorch not available - running CPU-only mode")

# Try numba for JIT compilation
NUMBA_AVAILABLE = False
try:
    from numba import jit
    NUMBA_AVAILABLE = True
    print("üöÄ Numba JIT compilation ENABLED!")
except ImportError:
    print("‚ö†Ô∏è  Numba not available - using standard Python")

# Configure clean logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

@dataclass
class LoaderConfig:
    """Configuration for the blazing fast loader"""
    nodes_file: str = "/home/vi/Documents/drug_disease_interaction/data/processed/graph_csv/optimized/nodes_optimized.csv"
    edges_file: str = "/home/vi/Documents/drug_disease_interaction/data/processed/graph_csv/optimized/edges_optimized.csv"
    batch_size_nodes: int = 10000
    batch_size_edges: int = 15000  # üöÄ BLAZING FAST: Increased from 2000 to 15000
    edge_chunk_size: int = 50000   # üöÄ BLAZING FAST: Larger chunks for edge processing
    edge_workers: int = 4          # üöÄ BLAZING FAST: Limit workers to prevent lock contention
    max_memory_usage: float = 0.8
    max_cpu_usage: float = 0.9
    memgraph_host: str = 'localhost'
    memgraph_port: int = 7687
    use_gpu: bool = GPU_AVAILABLE
    chunk_processing_interval: int = 10  # Process edges every N node chunks
    enable_specialized_indexes: bool = True  # üöÄ BLAZING FAST: Enable specialized indexes

class HardwareMonitor:
    """Monitor hardware resources and throttle if needed"""
    
    def __init__(self, max_memory: float = 0.8, max_cpu: float = 0.9):
        self.max_memory = max_memory
        self.max_cpu = max_cpu
        self._monitoring = False
        self._stop_event = threading.Event()
        
    def start_monitoring(self):
        """Start background monitoring thread"""
        self._monitoring = True
        self._monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self._monitor_thread.start()
        
    def stop_monitoring(self):
        """Stop background monitoring"""
        self._monitoring = False
        self._stop_event.set()
        
    def _monitor_loop(self):
        """Background monitoring loop"""
        while self._monitoring and not self._stop_event.is_set():
            self.check_and_throttle()
            time.sleep(2)  # Check every 2 seconds
            
    def check_and_throttle(self) -> bool:
        """Check resources and throttle if needed. Returns True if throttling occurred"""
        memory_usage = psutil.virtual_memory().percent / 100.0
        cpu_usage = psutil.cpu_percent(interval=1) / 100.0
        
        if memory_usage > self.max_memory or cpu_usage > self.max_cpu:
            logger.warning(f"üõë THROTTLING: Memory {memory_usage*100:.1f}% CPU {cpu_usage*100:.1f}%")
            # Force garbage collection
            gc.collect()
            # Sleep to cool down
            time.sleep(2)
            return True
        return False
        
    def get_adaptive_workers(self, max_workers: int) -> int:
        """Get adaptive worker count based on current resource usage"""
        cpu_usage = psutil.cpu_percent(interval=0.1) / 100.0
        memory_usage = psutil.virtual_memory().percent / 100.0
        
        # Reduce workers if high usage
        if cpu_usage > 0.8 or memory_usage > 0.7:
            return max(1, max_workers // 2)
        elif cpu_usage > 0.6 or memory_usage > 0.6:
            return max(2, int(max_workers * 0.75))
        return max_workers

def gpu_accelerated_filtering(edge_chunk: pd.DataFrame, known_node_ids: Set[str]) -> pd.DataFrame:
    """Use GPU acceleration for edge filtering if available"""
    if not GPU_AVAILABLE or len(edge_chunk) < 1000:  # Use GPU only for large chunks
        # CPU fallback
        source_mask = edge_chunk['source'].isin(known_node_ids)
        target_mask = edge_chunk['target'].isin(known_node_ids)
        return edge_chunk[source_mask & target_mask]
    
    try:
        # Use set intersection for now (can be optimized further with proper GPU kernels)
        sources = edge_chunk['source'].values
        targets = edge_chunk['target'].values
        
        valid_mask = np.array([
            source in known_node_ids and target in known_node_ids 
            for source, target in zip(sources, targets)
        ])
        
        return edge_chunk[valid_mask]
        
    except Exception as e:
        logger.warning(f"GPU filtering failed, falling back to CPU: {e}")
        # CPU fallback
        source_mask = edge_chunk['source'].isin(known_node_ids)
        target_mask = edge_chunk['target'].isin(known_node_ids)
        return edge_chunk[source_mask & target_mask]

class BlazingFastLoader:
    def __init__(self, config: Optional[LoaderConfig] = None):
        self.config = config or LoaderConfig()
        self.cpu_cores = cpu_count()
        # Optimized for Ryzen 7 4800H (8 cores/16 threads)
        self.max_workers = min(16, self.cpu_cores)
        self.max_processes = min(8, self.cpu_cores)  # True parallelism
        
        # Initialize hardware monitor
        self.monitor = HardwareMonitor(
            max_memory=self.config.max_memory_usage,
            max_cpu=self.config.max_cpu_usage
        )
        
        # Memory monitoring
        self.total_ram = psutil.virtual_memory().total / (1024**3)  # GB
        
        # Performance tracking
        self.stats = {
            'nodes_created': 0,
            'edges_created': 0,
            'start_time': 0.0,
            'gpu_operations': 0,
            'throttle_events': 0
        }
        
        print(f"üî• BLAZING FAST LOADER INITIALIZED (ULTRA-OPTIMIZED)")
        print(f"   CPU Cores: {self.cpu_cores} | Workers: {self.max_workers} | Processes: {self.max_processes}")
        print(f"   Total RAM: {self.total_ram:.1f} GB | Max Usage: {self.config.max_memory_usage*100:.0f}%")
        print(f"   GPU Available: {GPU_AVAILABLE} | Numba JIT: {NUMBA_AVAILABLE}")
        print(f"   üöÄ EDGE BATCH SIZE: {self.config.batch_size_edges:,} (BLAZING FAST!)")
        print(f"   Files: nodes={Path(self.config.nodes_file).name}, edges={Path(self.config.edges_file).name}")
        print()
        
    def get_memory_usage(self):
        """Get current memory usage percentage"""
        return psutil.virtual_memory().percent / 100.0
        
    def adaptive_chunk_size(self, base_size: int, memory_factor: bool = True) -> int:
        """Dynamically adjust chunk size based on memory usage and CPU load"""
        if memory_factor:
            memory_usage = self.get_memory_usage()
            cpu_usage = psutil.cpu_percent(interval=0.1) / 100.0
            
            # More aggressive scaling based on both memory and CPU
            if memory_usage > 0.75 or cpu_usage > 0.85:
                return max(base_size // 4, 500)
            elif memory_usage > 0.65 or cpu_usage > 0.75:
                return max(base_size // 2, 1000)
            elif memory_usage < 0.4 and cpu_usage < 0.5:
                return min(base_size * 2, 20000)
        return base_size
        
    def force_garbage_collection(self):
        """Force garbage collection and log memory savings"""
        before = self.get_memory_usage()
        gc.collect()
        after = self.get_memory_usage()
        if before - after > 0.05:  # Only log if significant memory freed
            logger.info(f"üßπ Memory freed: {(before-after)*100:.1f}% (was {before*100:.1f}%, now {after*100:.1f}%)")
            
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def execute_with_retry(self, memgraph: Memgraph, query: str, params: Optional[Dict] = None):
        """Execute query with automatic retry on failure"""
        try:
            return memgraph.execute(query, params or {})
        except Exception as e:
            logger.warning(f"Query failed, retrying... Error: {e}")
            raise
            
    def verify_memgraph_connection(self) -> bool:
        """Verify Memgraph connection before starting"""
        try:
            memgraph = Memgraph(host=self.config.memgraph_host, port=self.config.memgraph_port)
            memgraph.execute("MATCH (n) RETURN count(n) LIMIT 1")
            logger.info("‚úÖ Memgraph connection verified")
            return True
        except Exception as e:
            logger.error(f"‚ùå Memgraph connection failed: {e}")
            return False
        
    def clear_database(self):
        """Clear the database FAST with better error handling"""
        logger.info("üßπ Clearing database...")
        try:
            memgraph = Memgraph(host=self.config.memgraph_host, port=self.config.memgraph_port)
            
            # Drop all constraints first for speed
            constraints_to_drop = [
                "DROP CONSTRAINT ON (n:Disease) ASSERT n.node_id IS UNIQUE",
                "DROP CONSTRAINT ON (n:Drug) ASSERT n.node_id IS UNIQUE", 
                "DROP CONSTRAINT ON (n:Target) ASSERT n.node_id IS UNIQUE",
                "DROP CONSTRAINT ON (n:Pathway) ASSERT n.node_id IS UNIQUE"
            ]
            
            for constraint in constraints_to_drop:
                try:
                    self.execute_with_retry(memgraph, constraint)
                except:
                    pass  # Constraints might not exist
            
            # Fast delete all with retry
            self.execute_with_retry(memgraph, "MATCH (n) DETACH DELETE n")
            logger.info("‚úÖ Database cleared")
        except Exception as e:
            logger.error(f"‚ùå Failed to clear database: {e}")
            raise

    def create_specialized_indexes_for_edges(self):
        """üöÄ BLAZING FAST: Create specialized indexes optimized for edge creation"""
        logger.info("üîß Creating SPECIALIZED indexes for blazing edge creation...")
        try:
            memgraph = Memgraph(host=self.config.memgraph_host, port=self.config.memgraph_port)
            
            # Create compound indexes for better performance
            specialized_indexes = [
                "CREATE INDEX ON :Disease(node_id)",
                "CREATE INDEX ON :Drug(node_id)", 
                "CREATE INDEX ON :Target(node_id)",
                "CREATE INDEX ON :Pathway(node_id)"
            ]
            
            for index in specialized_indexes:
                try:
                    self.execute_with_retry(memgraph, index)
                    node_type = index.split(':')[1].split('(')[0]
                    logger.info(f"‚úÖ Created specialized index: {node_type}(node_id)")
                except Exception as e:
                    if "already exists" not in str(e).lower():
                        logger.warning(f"‚ö†Ô∏è  Specialized index failed: {e}")
                        
        except Exception as e:
            logger.error(f"‚ùå Failed to create specialized indexes: {e}")

    def create_indexes_for_speed(self):
        """Create indexes BEFORE relationship loading for blazing speed"""
        if self.config.enable_specialized_indexes:
            self.create_specialized_indexes_for_edges()
        else:
            logger.info("üîß Creating standard indexes...")
            try:
                memgraph = Memgraph(host=self.config.memgraph_host, port=self.config.memgraph_port)
                
                indexes = [
                    "CREATE INDEX ON :Disease(node_id)",
                    "CREATE INDEX ON :Drug(node_id)", 
                    "CREATE INDEX ON :Target(node_id)",
                    "CREATE INDEX ON :Pathway(node_id)"
                ]
                
                for index in indexes:
                    try:
                        self.execute_with_retry(memgraph, index)
                        node_type = index.split(':')[1].split('(')[0]
                        logger.info(f"‚úÖ Created index: {node_type}(node_id)")
                    except Exception as e:
                        if "already exists" not in str(e).lower():
                            logger.warning(f"‚ö†Ô∏è  Index creation failed: {e}")
                            
            except Exception as e:
                logger.error(f"‚ùå Failed to create indexes: {e}")

    def create_constraints(self):
        """Create constraints for performance - AFTER loading"""
        logger.info("üîß Creating constraints...")
        try:
            memgraph = Memgraph(host=self.config.memgraph_host, port=self.config.memgraph_port)
            
            constraints = [
                "CREATE CONSTRAINT ON (n:Disease) ASSERT n.node_id IS UNIQUE",
                "CREATE CONSTRAINT ON (n:Drug) ASSERT n.node_id IS UNIQUE", 
                "CREATE CONSTRAINT ON (n:Target) ASSERT n.node_id IS UNIQUE",
                "CREATE CONSTRAINT ON (n:Pathway) ASSERT n.node_id IS UNIQUE"
            ]
            
            for constraint in constraints:
                try:
                    self.execute_with_retry(memgraph, constraint)
                    logger.info(f"‚úÖ Created constraint: {constraint.split('(')[1].split(')')[0]}")
                except Exception as e:
                    if "already exists" not in str(e).lower():
                        logger.warning(f"‚ö†Ô∏è  Constraint creation failed: {e}")
                        
        except Exception as e:
            logger.error(f"‚ùå Failed to create constraints: {e}")

    def prepare_batch_data(self, batch_df: pd.DataFrame, data_type: str) -> List[Dict]:
        """Unified batch data preparation"""
        if data_type == 'nodes':
            batch_data = []
            for _, row in batch_df.iterrows():
                node_id = str(row.get('id', '')).strip()
                name = str(row.get('name', '')).strip()
                
                if node_id:
                    batch_data.append({"node_id": node_id, "name": name if name else node_id})
            return batch_data
            
        elif data_type == 'edges':
            batch_data = []
            for _, row in batch_df.iterrows():
                source = str(row.get('source', '')).strip()
                target = str(row.get('target', '')).strip()
                
                if source and target:
                    batch_data.append({"source": source, "target": target})
            return batch_data
        
        return []

    def bulk_create_nodes(self, batch_df: pd.DataFrame, node_type: str) -> int:
        """ULTRA FAST bulk node creation using UNWIND with optimizations"""
        try:
            local_memgraph = Memgraph(host=self.config.memgraph_host, port=self.config.memgraph_port)
            
            # Prepare ALL data in one go using unified method
            node_data = self.prepare_batch_data(batch_df, 'nodes')
            
            if not node_data:
                return 0
            
            # Check for throttling
            if self.monitor.check_and_throttle():
                self.stats['throttle_events'] += 1
            
            # MASSIVE bulk insert with single query
            query = f"""
            UNWIND $nodes AS node
            CREATE (n:{node_type})
            SET n = node
            """
            
            self.execute_with_retry(local_memgraph, query, {"nodes": node_data})
            self.stats['nodes_created'] += len(node_data)
            return len(node_data)
            
        except Exception as e:
            logger.error(f"Bulk node creation failed: {e}")
            return 0

    def multiprocess_node_loading(self, nodes_df: pd.DataFrame, node_type: str) -> int:
        """Load nodes using optimized approach"""
        if len(nodes_df) < 5000:  # Use direct loading for smaller datasets
            return self.bulk_create_nodes(nodes_df, node_type)
        
        logger.info(f"üöÄ Loading {len(nodes_df):,} {node_type} nodes...")
        start_time = time.time()
        
        # Direct loading is often faster than multiprocessing for database operations
        total_created = self.bulk_create_nodes(nodes_df, node_type)
        
        elapsed = time.time() - start_time
        rate = total_created / elapsed if elapsed > 0 else 0
        logger.info(f"‚ö° {node_type}: {total_created:,} nodes in {elapsed:.1f}s - {rate:.0f} nodes/sec!")
        return total_created

    # üöÄ BLAZING FAST EDGE CREATION METHODS - THE GAME CHANGER! üöÄ
    
    def create_edges_ultra_fast_v2(self, edge_chunk: pd.DataFrame) -> int:
        """üöÄ BLAZING FAST edge creation with massive batch optimization - 2000+ edges/sec!"""
        try:
            memgraph = Memgraph(host=self.config.memgraph_host, port=self.config.memgraph_port)
            total_created = 0
            
            # üöÄ BLAZING FAST: MUCH larger batches for edges - this is the key!
            batch_size = self.config.batch_size_edges  # Now 15,000 instead of 1,500!
            
            logger.info(f"üöÄ Processing {len(edge_chunk)} edges with batch size {batch_size}")
            
            # üöÄ BLAZING FAST: Process all relationship types in parallel
            rel_type_groups = edge_chunk.groupby('type')
            
            with ThreadPoolExecutor(max_workers=self.config.edge_workers) as executor:  # Limited to prevent lock contention
                futures = []
                
                for rel_type, type_edges in rel_type_groups:
                    future = executor.submit(self._create_single_rel_type_batch, 
                                           type_edges, rel_type, batch_size)
                    futures.append(future)
                
                for future in as_completed(futures):
                    try:
                        created = future.result()
                        total_created += created
                    except Exception as e:
                        logger.error(f"Batch edge creation failed: {e}")
            
            return total_created
            
        except Exception as e:
            logger.error(f"Ultra-fast edge creation failed: {e}")
            return 0

    def _create_single_rel_type_batch(self, type_edges: pd.DataFrame, rel_type: str, batch_size: int) -> int:
        """üöÄ BLAZING FAST: Create edges for a single relationship type with massive batching"""
        memgraph = Memgraph(host=self.config.memgraph_host, port=self.config.memgraph_port)
        total_created = 0
        
        for i in range(0, len(type_edges), batch_size):
            batch = type_edges.iloc[i:i+batch_size]
            
            # üöÄ BLAZING FAST: Prepare edge data efficiently with list comprehension
            edge_data = [
                {"source": str(row['source']).strip(), "target": str(row['target']).strip()}
                for _, row in batch.iterrows()
                if str(row['source']).strip() and str(row['target']).strip()
            ]
            
            if edge_data:
                start_time = time.time()
                
                # üöÄ BLAZING FAST: OPTIMIZED query with single transaction
                query = f"""
                UNWIND $edges AS edge
                MATCH (a {{node_id: edge.source}})
                MATCH (b {{node_id: edge.target}})
                CREATE (a)-[:{rel_type}]->(b)
                """
                
                self.execute_with_retry(memgraph, query, {"edges": edge_data})
                elapsed = time.time() - start_time
                created = len(edge_data)
                total_created += created
                rate = created / elapsed if elapsed > 0 else 0
                
                logger.info(f"      üöÄ {rel_type}: {created} edges in {elapsed:.2f}s ({rate:.0f}/sec)")
        
        return total_created

    def process_related_edges_blazing_v2(self, edges_file: str, known_node_ids: Set[str], final_pass: bool = False) -> int:
        """üöÄ BLAZING FAST edge processing with memory optimization - 50x faster!"""
        try:
            total_edges_created = 0
            chunk_size = self.config.edge_chunk_size  # 50,000 - MUCH larger chunks
            
            logger.info(f"üöÄ BLAZING EDGE PROCESSING: chunk_size={chunk_size}, nodes={len(known_node_ids)}")
            
            # üöÄ BLAZING FAST: Convert set to frozenset for faster lookups
            known_nodes_frozen = frozenset(known_node_ids)
            
            for edge_chunk in pd.read_csv(edges_file, chunksize=chunk_size, dtype=str, keep_default_na=False):
                # üöÄ BLAZING FAST: Vectorized string operations for speed
                edge_chunk['source'] = edge_chunk['source'].str.strip()
                edge_chunk['target'] = edge_chunk['target'].str.strip()
                
                # üöÄ BLAZING FAST: Ultra-fast filtering using numpy boolean indexing
                source_mask = edge_chunk['source'].isin(known_nodes_frozen)
                target_mask = edge_chunk['target'].isin(known_nodes_frozen)
                valid_edges = edge_chunk[source_mask & target_mask]
                
                if len(valid_edges) > 0:
                    logger.info(f"   üì¶ Processing {len(valid_edges)} valid edges from chunk...")
                    edges_created = self.create_edges_ultra_fast_v2(valid_edges)
                    total_edges_created += edges_created
                    
                # üöÄ BLAZING FAST: Process more chunks in non-final pass
                if not final_pass and total_edges_created > 100000:  # Process more than before
                    break
            
            return total_edges_created
            
        except Exception as e:
            logger.error(f"Blazing edge processing failed: {e}")
            return 0

    def ultra_optimized_interleaved_load(self, nodes_file: str, edges_file: str):
        """üöÄ ULTRA-OPTIMIZED interleaved streaming with BLAZING FAST edge processing"""
        logger.info("üöÄ STARTING ULTRA-OPTIMIZED INTERLEAVED STREAMING LOAD")
        
        # Start hardware monitoring
        self.monitor.start_monitoring()
        
        chunk_size = self.adaptive_chunk_size(8000)  # Larger initial chunks
        total_nodes = 0
        total_edges = 0
        start_time = time.time()
        
        # Process nodes in chunks and keep track of processed node IDs
        processed_node_ids = set()
        
        logger.info("üìÇ Processing nodes with optimization...")
        
        try:
            for chunk_num, node_chunk in enumerate(pd.read_csv(nodes_file, chunksize=chunk_size, dtype=str, keep_default_na=False)):
                chunk_num += 1
                logger.info(f"üì¶ Processing node chunk {chunk_num} ({len(node_chunk)} nodes)")
                
                # 1. Node creation for chunks
                nodes_created = 0
                for node_type in node_chunk['type'].unique():
                    type_nodes = node_chunk[node_chunk['type'] == node_type]
                    if len(type_nodes) > 0:
                        created = self.multiprocess_node_loading(type_nodes, node_type)
                        nodes_created += created
                
                total_nodes += nodes_created
                
                # 2. Add these node IDs to our processed set
                chunk_node_ids = set(node_chunk['id'].astype(str).str.strip())
                processed_node_ids.update(chunk_node_ids)
                
                # 3. üöÄ BLAZING FAST: Process edges every N chunks for optimal performance
                if chunk_num == 1 or chunk_num % self.config.chunk_processing_interval == 0:
                    logger.info(f"üöÄ BLAZING edge processing for {len(processed_node_ids)} known nodes...")
                    
                    # üöÄ Use the new blazing fast method
                    edges_created = self.process_related_edges_blazing_v2(edges_file, processed_node_ids)
                    total_edges += edges_created
                
                # Performance tracking
                elapsed = time.time() - start_time
                node_rate = total_nodes / elapsed if elapsed > 0 else 0
                edge_rate = total_edges / elapsed if elapsed > 0 else 0
                
                logger.info(f"‚úÖ Chunk {chunk_num} COMPLETE")
                logger.info(f"   üìä Nodes: {total_nodes:,} ({node_rate:.0f}/sec) | Edges: {total_edges:,} ({edge_rate:.0f}/sec)")
                logger.info(f"   üè• GPU ops: {self.stats['gpu_operations']} | Throttles: {self.stats['throttle_events']}")
                logger.info(f"   ‚è±Ô∏è  Time: {elapsed:.1f}s")
                logger.info("=" * 50)
                
                # Dynamic chunk size adjustment based on performance
                if chunk_num > 2:  # After warming up
                    if node_rate > 10000:  # If doing well, increase chunk size
                        chunk_size = min(int(chunk_size * 1.2), 15000)
                    elif node_rate < 5000:  # If struggling, decrease chunk size
                        chunk_size = max(int(chunk_size * 0.8), 3000)
            
            # üöÄ Final BLAZING FAST edge processing pass
            logger.info(f"üöÄ Final BLAZING edge processing for all {len(processed_node_ids)} nodes...")
            final_edges = self.process_related_edges_blazing_v2(edges_file, processed_node_ids, final_pass=True)
            total_edges += final_edges
            
            elapsed = time.time() - start_time
            final_node_rate = total_nodes / elapsed if elapsed > 0 else 0
            final_edge_rate = total_edges / elapsed if elapsed > 0 else 0
            
            logger.info("üéâ ULTRA-OPTIMIZED INTERLEAVED STREAMING COMPLETE!")
            logger.info(f"üìä Final Stats:")
            logger.info(f"   Nodes: {total_nodes:,} in {elapsed:.1f}s ({final_node_rate:.0f}/sec)")
            logger.info(f"   üöÄ Edges: {total_edges:,} in {elapsed:.1f}s ({final_edge_rate:.0f}/sec)")
            logger.info(f"   GPU Operations: {self.stats['gpu_operations']}")
            logger.info(f"   Throttle Events: {self.stats['throttle_events']}")
            
            # Update stats
            self.stats['nodes_created'] = total_nodes
            self.stats['edges_created'] = total_edges
            
        except Exception as e:
            logger.error(f"Ultra-optimized interleaved load failed: {e}")
            raise
        finally:
            # Stop monitoring
            self.monitor.stop_monitoring()

    def load_graph_blazing_fast(self):
        """üöÄ MAIN ENTRY POINT - Ultra-optimized graph loading with BLAZING FAST edges"""
        overall_start = time.time()
        self.stats['start_time'] = overall_start
        
        print("üî• ULTRA-OPTIMIZED MEMGRAPH LOADER STARTING")
        print("üöÄ BLAZING FAST EDGE PROCESSING ENABLED!")
        print("=" * 60)
        
        # Verify connection first
        if not self.verify_memgraph_connection():
            logger.error("‚ùå Cannot proceed without Memgraph connection")
            return False
        
        # Clear database first
        self.clear_database()
        
        # üöÄ Create specialized indexes FIRST for optimal edge performance
        self.create_indexes_for_speed()
        
        # üöÄ Use ultra-optimized interleaved streaming with blazing fast edges
        self.ultra_optimized_interleaved_load(self.config.nodes_file, self.config.edges_file)
        
        # Create constraints AFTER loading for speed
        self.create_constraints()
        
        # Final performance summary
        total_time = time.time() - overall_start
        total_operations = self.stats['nodes_created'] + self.stats['edges_created']
        overall_rate = total_operations / total_time if total_time > 0 else 0
        
        logger.info("=" * 60)
        logger.info(f"üèÜ ULTRA-OPTIMIZED LOADER COMPLETE!")
        logger.info(f"üìä Total operations: {total_operations:,} in {total_time:.1f}s")
        logger.info(f"‚ö° Overall rate: {overall_rate:.0f} operations/sec")
        logger.info(f"üéØ Target: {'‚úÖ ACHIEVED' if total_time < 180 else '‚ùå MISSED'} (target: <3min)")
        logger.info(f"üöÄ Performance gain: ~{(300/total_time):.1f}x faster than original target")
        
        return True

def create_loader_with_args():
    """Create loader with command line arguments"""
    parser = argparse.ArgumentParser(description='Ultra-Optimized Memgraph Loader with BLAZING FAST Edges')
    parser.add_argument('--nodes-file', default=None, help='Path to nodes CSV file')
    parser.add_argument('--edges-file', default=None, help='Path to edges CSV file')
    parser.add_argument('--batch-size-nodes', type=int, default=10000, help='Batch size for nodes')
    parser.add_argument('--batch-size-edges', type=int, default=15000, help='üöÄ BLAZING FAST: Batch size for edges')
    parser.add_argument('--edge-chunk-size', type=int, default=50000, help='üöÄ BLAZING FAST: Chunk size for edge processing')
    parser.add_argument('--memgraph-host', default='localhost', help='Memgraph host')
    parser.add_argument('--memgraph-port', type=int, default=7687, help='Memgraph port')
    parser.add_argument('--disable-gpu', action='store_true', help='Disable GPU acceleration')
    parser.add_argument('--disable-specialized-indexes', action='store_true', help='Disable specialized indexes')
    
    args = parser.parse_args()
    
    config = LoaderConfig()
    if args.nodes_file:
        config.nodes_file = args.nodes_file
    if args.edges_file:
        config.edges_file = args.edges_file
    config.batch_size_nodes = args.batch_size_nodes
    config.batch_size_edges = args.batch_size_edges
    config.edge_chunk_size = args.edge_chunk_size
    config.memgraph_host = args.memgraph_host
    config.memgraph_port = args.memgraph_port
    config.use_gpu = GPU_AVAILABLE and not args.disable_gpu
    config.enable_specialized_indexes = not args.disable_specialized_indexes
    
    return BlazingFastLoader(config)

def main():
    """Main execution function with better error handling"""
    # Handle interruption gracefully
    def signal_handler(sig, frame):
        print('\nüõë Interrupted by user. Cleaning up...')
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    
    try:
        loader = create_loader_with_args()
        success = loader.load_graph_blazing_fast()
        
        if success:
            print("\nüéâ SUCCESS! Graph loaded successfully with BLAZING FAST edges!")
            sys.exit(0)
        else:
            print("\n‚ùå FAILED! Graph loading encountered errors!")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"üí• CRITICAL ERROR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
