# docker/docker-compose.yml - CORRECTED VERSION
services:
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DDI_OLLAMA_URL=http://ollama:11434
      - DDI_DB_NEO4J_URI=bolt://neo4j:7687
      - DDI_DB_NEO4J_USER=neo4j
      - DDI_DB_NEO4J_PASSWORD=123lol123
      - DDI_DB_WEAVIATE_URL=http://weaviate:8080
      - DDI_REDIS_URL=redis://redis:6379
    depends_on:
      weaviate: { condition: service_healthy }
      neo4j: { condition: service_healthy }
      ollama: { condition: service_healthy }
      redis: { condition: service_healthy }
    restart: unless-stopped

  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.25.0
    ports:
      - "8080:8080"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      # ✅ Tell Weaviate to store its data in /data inside the container for consistency.
      PERSISTENCE_DATA_PATH: '/data'
      DEFAULT_VECTORIZER_MODULE: 'none'
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      # ✅ Use the portable path from the .env file.
      - ${PROJECT_DATA_PATH}/databases/vector:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/ready"]
      interval: 10s
      timeout: 5s
      retries: 6

  neo4j:
    image: neo4j:5.13
    environment:
      - NEO4J_AUTH=neo4j/123lol123
      - NEO4J_server_memory_heap_initial__size=1G
      - NEO4J_server_memory_heap_max__size=2G
      - NEO4J_server_memory_pagecache_size=1G
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      # ✅ Use the portable path from the .env file.
      - ${PROJECT_DATA_PATH}/databases/neo4j:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7474"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      # Use a named volume for Ollama models as the path is internal to the image.
      - ollama_data:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 20s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

# Define the named volume used by Ollama.
volumes:
  ollama_data:
